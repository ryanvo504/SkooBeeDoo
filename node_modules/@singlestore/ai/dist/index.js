"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  AI: () => AI,
  ChatCompletionTool: () => ChatCompletionTool,
  ChatCompletionsManager: () => ChatCompletionsManager,
  EmbeddingsManager: () => EmbeddingsManager,
  MessageLengthExceededError: () => MessageLengthExceededError,
  MessagesLengthExceededError: () => MessagesLengthExceededError,
  TextSplitter: () => TextSplitter,
  parseLengthErrorMessage: () => parseLengthErrorMessage
});
module.exports = __toCommonJS(src_exports);

// src/chat-completions/manager.ts
var ChatCompletionsManager = class {
  tools = void 0;
  initTools(tools) {
    this.tools = tools;
  }
  async handleStream(stream, onChunk) {
    let completion = { content: "" };
    for await (const chunk of stream) {
      completion = { ...completion, ...chunk, content: `${completion.content}${chunk.content}` };
      await onChunk?.(chunk);
    }
    return completion;
  }
};

// src/chat-completions/openai.ts
var import_openai = require("openai");
var import_zod_to_json_schema = __toESM(require("zod-to-json-schema"));

// src/chat-completions/errors/lib/parse-length-error-message.ts
function parseLengthErrorMessage(message) {
  const [maxLength, length] = [...message.matchAll(/length\s+(\d+)/g)].map((match) => Number(match[1]));
  return [length, maxLength];
}

// src/chat-completions/errors/message-length-exceeded.ts.ts
var MessageLengthExceededError = class extends Error {
  constructor(message, options) {
    super(message, { cause: options?.cause });
    this.message = message;
    this.name = "MessageLengthExceededError";
    this.length = options?.length;
    this.maxLength = options?.maxLength;
  }
  length;
  maxLength;
  cause;
};

// src/chat-completions/errors/messages-length-exceeded.ts
var MessagesLengthExceededError = class extends Error {
  constructor(message, options) {
    super(message, { cause: options?.cause });
    this.message = message;
    this.name = "MessagesLengthExceededError";
    this.length = options?.length;
    this.maxLength = options?.maxLength;
  }
  length;
  maxLength;
  cause;
};

// src/chat-completions/openai.ts
var OpenAIChatCompletions = class extends ChatCompletionsManager {
  constructor(_openai) {
    super();
    this._openai = _openai;
  }
  getModels() {
    return [
      "gpt-4o",
      "gpt-4o-2024-05-13",
      "gpt-4o-2024-08-06",
      "gpt-4o-mini",
      "gpt-4o-mini-2024-07-18",
      "gpt-4-turbo",
      "gpt-4-turbo-2024-04-09",
      "gpt-4-turbo-preview",
      "gpt-4-0125-preview",
      "gpt-4-1106-preview",
      "gpt-4",
      "gpt-4-0613",
      "gpt-3.5-turbo-0125",
      "gpt-3.5-turbo",
      "gpt-3.5-turbo-1106",
      "gpt-3.5-turbo-instruct"
    ];
  }
  async create({
    prompt,
    systemRole,
    messages,
    tools,
    toolCallHandlers,
    toolCallResultHandlers,
    ...params
  }) {
    let _messages = [];
    if (systemRole) _messages.push({ role: "system", content: systemRole });
    if (messages?.length) _messages = [..._messages, ...messages];
    if (prompt) _messages.push({ role: "user", content: prompt });
    let _tools = [];
    if (this.tools?.length) _tools = [..._tools, ...this.tools];
    if (tools?.length) _tools = [..._tools, ...tools];
    let response;
    try {
      response = await this._openai.chat.completions.create({
        model: "gpt-4o-mini",
        temperature: 0,
        ...params,
        messages: _messages,
        tools: _tools.length ? _tools.map(({ name, description, params: params2 }) => ({
          type: "function",
          function: { name, description, parameters: params2 ? (0, import_zod_to_json_schema.default)(params2) : void 0 }
        })) : void 0
      });
    } catch (error) {
      if (error instanceof import_openai.BadRequestError) {
        if (error.code === "array_above_max_length") {
          const [length, maxLength] = parseLengthErrorMessage(error.message);
          throw new MessagesLengthExceededError(error.message, { length, maxLength, cause: error });
        }
        if (error.code === "string_above_max_length") {
          const [length, maxLength] = parseLengthErrorMessage(error.message);
          throw new MessageLengthExceededError(error.message, { length, maxLength, cause: error });
        }
      }
      throw error;
    }
    const handleToolCalls = (toolCalls = []) => {
      return Promise.all(
        toolCalls.map(async (call) => {
          const _call = { ...call, id: call.id || "" };
          if (!call.function) {
            throw new Error(`Invalid tool call: ${JSON.stringify(call)}`);
          }
          let params2;
          if (call.function.arguments) {
            try {
              params2 = JSON.parse(call.function.arguments);
            } catch (error) {
              throw new Error(`Invalid parameters provided for the "${call.function.name}" tool.`, { cause: error });
            }
          }
          const tool = _tools.find(({ name }) => name === call.function?.name);
          if (!tool) {
            throw new Error(`The "${call.function.name}" tool is undefined.`);
          }
          try {
            await toolCallHandlers?.[tool.name]?.(tool, params2);
            const result = await tool.call(params2);
            await toolCallResultHandlers?.[tool.name]?.(tool, result, params2);
            return [{ tool, params: params2, value: result.value }, _call];
          } catch (error) {
            let _error = error;
            if (typeof error !== "string") {
              if (error instanceof Error) {
                _error = `Error: ${error.message}`;
              } else {
                try {
                  _error = JSON.stringify(error, Object.getOwnPropertyNames(error));
                } catch (error2) {
                  _error = JSON.stringify(error2, Object.getOwnPropertyNames(error2));
                }
              }
            }
            return [{ tool, params: params2, error: _error }, _call];
          }
        })
      );
    };
    const handleToolCallResults = (results, message) => {
      return this.create({
        ...params,
        tools,
        messages: [
          ..._messages,
          message,
          ...results.map(([result, { id }]) => {
            return {
              role: "tool",
              tool_call_id: id,
              content: "error" in result ? result.error : result.value
            };
          })
        ]
      });
    };
    if (typeof response === "object" && response && "choices" in response) {
      const message = response.choices[0]?.message;
      if (message && "tool_calls" in message && message.tool_calls?.length) {
        const toolCallResults = await handleToolCalls(message.tool_calls);
        return await handleToolCallResults(toolCallResults, message);
      }
      return { content: message?.content || "" };
    }
    async function* handleStream(stream) {
      let delta = void 0;
      for await (const chunk of stream) {
        const _delta = chunk.choices[0]?.delta;
        if (!delta) delta = { ..._delta, content: _delta?.content || "", tool_calls: [] };
        if (_delta && "tool_calls" in _delta && _delta.tool_calls?.length) {
          for (const toolCall of _delta.tool_calls) {
            if (!delta || !delta.tool_calls) break;
            const deltaToolCall = delta.tool_calls[toolCall.index] || { function: { arguments: "" } };
            delta.tool_calls[toolCall.index] = {
              ...deltaToolCall,
              ...toolCall,
              function: {
                ...deltaToolCall.function,
                ...toolCall.function,
                arguments: `${deltaToolCall.function?.arguments || ""}${toolCall.function?.arguments || ""}`
              }
            };
          }
        } else {
          yield { content: _delta?.content || "" };
        }
      }
      if (delta?.tool_calls?.length) {
        const toolCallResults = await handleToolCalls(delta.tool_calls);
        const toolCallResultsStream = await handleToolCallResults(toolCallResults, delta);
        for await (const chunk of toolCallResultsStream) yield chunk;
      }
    }
    return handleStream(response);
  }
};

// src/chat-completions/tool.ts
var ChatCompletionTool = class {
  name;
  description;
  params;
  call;
  constructor(config) {
    this.name = config.name;
    this.description = config.description;
    this.params = config.params;
    this.call = config.call;
  }
};

// src/embeddings/manager.ts
var EmbeddingsManager = class {
};

// src/embeddings/openai.ts
var OpenAIEmbeddingsManager = class extends EmbeddingsManager {
  constructor(_openai) {
    super();
    this._openai = _openai;
  }
  getModels() {
    return ["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"];
  }
  async create(input, params) {
    const _input = Array.isArray(input) ? input : [input];
    const response = await this._openai.embeddings.create({ model: "text-embedding-3-small", ...params, input: _input });
    return response.data.map((data) => data.embedding);
  }
};

// src/text-splitter/text-splitter.ts
var TextSplitter = class {
  split(text, options = {}) {
    const { chunkSize = 1024, delimiter = /(?<=[.!?])[\s\n]+/ } = options;
    const chunks = [];
    let accChunk = [];
    let accChunkLength = 0;
    for (const chunk of text.split(delimiter)) {
      if (chunk.length > chunkSize) {
        let subChunks = [];
        if (delimiter === " ") {
          subChunks.push(chunk);
        } else {
          subChunks = this.split(chunk, { chunkSize, delimiter: " " });
        }
        if (accChunkLength > 0) {
          chunks.push(accChunk.join(" "));
          accChunk = [];
          accChunkLength = 0;
        }
        chunks.push(...subChunks);
      } else if (accChunkLength + chunk.length <= chunkSize) {
        accChunk.push(chunk);
        accChunkLength += chunk.length;
      } else {
        chunks.push(accChunk.join(" "));
        accChunk = [chunk];
        accChunkLength = chunk.length;
      }
    }
    if (accChunk.length > 0) {
      chunks.push(accChunk.join(" "));
    }
    return chunks;
  }
};

// src/ai.ts
var import_openai2 = __toESM(require("openai"));
var AI = class {
  embeddings;
  chatCompletions;
  textSplitter;
  constructor(config) {
    const openai = new import_openai2.default({ apiKey: config.openAIApiKey });
    this.chatCompletions = config.chatCompletionsManager ?? new OpenAIChatCompletions(openai);
    this.embeddings = config.embeddingsManager ?? new OpenAIEmbeddingsManager(openai);
    this.textSplitter = config.textSplitter ?? new TextSplitter();
    if (config.chatCompletionTools?.length) {
      this.chatCompletions.initTools(config.chatCompletionTools);
    }
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  AI,
  ChatCompletionTool,
  ChatCompletionsManager,
  EmbeddingsManager,
  MessageLengthExceededError,
  MessagesLengthExceededError,
  TextSplitter,
  parseLengthErrorMessage
});
//# sourceMappingURL=index.js.map